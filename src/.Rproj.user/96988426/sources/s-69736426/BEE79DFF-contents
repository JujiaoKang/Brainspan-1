export PATH=/cluster/apps/bin/:$PATH

#platform='hg38'
platform='hg19'
result="result/PYGL_${platform}/"

## 1000genome, 2504 samples, phase3
# vcf version issue
#chr_list="1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X"
#chr_list="1 2 3 4 5 6 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X"
#for i in $chr_list
#do 
#	zcat data/1000g/20190312/ALL.chr$i.shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.gz | sed 's/^##fileformat=VCFv4.3/##fileformat=VCFv4.2/' | /cluster/apps/bin/bgzip -c >data/1000g/20190312/ALL.chr$i.shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf4.2.gz &
#done

### hg38 chr14 2781457 155703812
# sample info: /cluster/home/luyulan/project/Combined_Pipeline/data/db_LZX/Genome1000_Phase3/input/Sample_infor.txt
perl src/extract_gene_from_vcf.pl data/1000g/20130502/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5.20130502.genotypes.vcf.gz $result/PYGL_1000g.vcf.gz PYGL hg19

# transfer to plink
vcftools --gzvcf $result/PYGL_1000g.vcf.gz --plink --out $result/PYGL_1000g.plink
# update ped file
perl src/modify_ped.pl data/integrated_call_samples_v2.20130502.ALL.ped $result/PYGL_1000g.plink.ped >tmp.ped
mv tmp.ped $result/PYGL_1000g.plink.ped
plink --file $result/PYGL_1000g.plink --biallelic-only --make-bed --out $result/PYGL_1000g.plink
# remove dup positions
#plink --bfile $result/PYGL_1000g.plink --list-duplicate-vars --out test
# extract EAS samples, 1 or M=male; 2 or F=female
#
#pop='CHB' ## CHB China JPT EAS EUR AMR  AFR SAS
pop_list="CHB JPT"
for pop in $pop_list
do
	grep $pop data/integrated_call_samples_v2.20130502.ALL.ped |cut -f 1 >data/$pop\_sample.txt;
	grep -f data/${pop}_sample.txt data/integrated_call_samples_v2.20130502.ALL.ped | cut -f 1,2 >data/${pop}_sample.2.txt;
done

pop_list="China EAS EUR AMR AFR SAS"
for pop in $pop_list
do
	grep -w -f data/$pop.txt data/integrated_call_samples_v2.20130502.ALL.ped |cut -f 1 >data/$pop\_sample.txt;
	grep -w -f data/${pop}_sample.txt data/integrated_call_samples_v2.20130502.ALL.ped | cut -f 1,2 >data/${pop}_sample.2.txt;
done

pop='ALL'
cut -f 1 data/integrated_call_samples_v2.20130502.ALL.ped >data/${pop}_sample.txt
grep -f data/${pop}_sample.txt data/integrated_call_samples_v2.20130502.ALL.ped | cut -f 1,2 >data/${pop}_sample.2.txt;

pop_list="CHB China JPT EAS EUR AMR AFR SAS ALL"
for pop in $pop_list
do
	plink --bfile $result/PYGL_1000g.plink --keep data/${pop}_sample.2.txt --snps-only --make-bed --out $result/PYGL_1000g_${pop}.plink 
	# basic statistics
	plink --bfile $result/PYGL_1000g_${pop}.plink --snps-only --freq --out $result/PYGL_1000g_${pop}.plink.ori_frq
	plink --bfile $result/PYGL_1000g_${pop}.plink --snps-only --maf 0.001 --make-bed --out $result/PYGL_1000g_${pop}.plink 
	#plink --bfile $result/PYGL_1000g_${pop}.plink --freq --hardy --hwe 0.001 --mendel --ibc --het --make-bed --out $result/PYGL_1000g_${pop}.plink
	# calculate LD 
	plink --bfile $result/PYGL_1000g_${pop}.plink --r2 --ld-window-r2 0 --out $result/PYGL_1000g_${pop}.ld 
	# calculate haplotype block
	plink --bfile $result/PYGL_1000g_${pop}.plink --blocks 'no-pheno-req' --out $result/PYGL_1000g_${pop}.blocks
done

################# for our CCGT datasets, WES/Panel --> hard to calculate haplotype !!!!
# original pedigree file
#cat /cluster/home/dongxinran/project/hg38_all/data/ped/*.ped | sort | uniq >data/all_CCGT.ped
cp /cluster/home/dongxinran/project/hg38_all/all.ped data/all_CCGT.ped

#########################################
################# for our WES/CES CCGT database
## /cluster/home/dongxinran/project/hg38_all/all_denovo_file.txt
#perl src/batch.pl /cluster/home/dongxinran/project/hg38_all/all_denovo_file.txt PYGL >task/PYGL.sh
#source task/PYGL.sh
#vcf_file=`ls tmp/PYGL*vcf.gz`
#CCGT_prefix='CCGT_PYGL.hg38'

##########################################################################################################################################
################# for our WGS CCGT database
# /cluster/home/wangyaqiong/WGS/tracking/data/WGS_file_path_current_YW.tsv
# grep s394g /cluster/home/wangyaqiong/WGS/tracking/data/WGS_file_path_current_YW.tsv  | grep -v "Index" |  grep -v "NotFound" | cut -f 1 >rm.txt
# grep -v rm.txt /cluster/home/wangyaqiong/WGS/tracking/data/WGS_file_path_current_YW.tsv
# use.txt
# # BSL第10列，s394g开头的
perl src/batch_WGS.pl /cluster/home/wangyaqiong/WGS/tracking/data/WGS_file_path_current_YW.tsv  PYGL >task/PYGL_WGS.sh
cat task/PYGL_WGS.sh  | parallel -j 8 & ## 2072 samples
#
vcf_file=`ls tmp_WGS/PYGL*vcf.gz | grep -f use.txt` 
ls tmp_WGS/PYGL*vcf.gz | grep -f use.txt| awk -F "\t" {'print "tabix -f "$1'} >tmp.sh
cat tmp.sh | parallel -j 8 &
##
platform='hg38'
result="result/PYGL_${platform}/"
CCGT_prefix='CCGT_PYGL_WGS.hg38'

###########
# merge vcf (--missing-to-ref)
bcftools merge --missing-to-ref --force-samples $vcf_file -o $result/$CCGT_prefix.vcf
rm $result/$CCGT_prefix.vcf.gz;bgzip $result/$CCGT_prefix.vcf;tabix $result/$CCGT_prefix.vcf.gz
bcftools norm -f /cluster/apps/refseq/GATK4/hg38/Homo_sapiens_assembly38.fasta $result/$CCGT_prefix.vcf.gz | bgzip -c >$result/$CCGT_prefix.norm.vcf.gz

## prepare ped file
# real sample in vcf
bcftools query -l $result/$CCGT_prefix.norm.vcf.gz |grep -v ":">data/CCGT.list
# remove dup samples
bcftools view -S data/CCGT.list -o $result/$CCGT_prefix.norm_use.vcf $result/$CCGT_prefix.norm.vcf.gz
rm $result/$CCGT_prefix.norm_use.vcf.gz;bgzip $result/$CCGT_prefix.norm_use.vcf;tabix $result/$CCGT_prefix.norm_use.vcf.gz
# transfer to plink and update ped file
vcftools --gzvcf $result/$CCGT_prefix.norm_use.vcf.gz --plink --out $result/$CCGT_prefix.plink
perl src/modify_ped.pl data/all_CCGT.ped $result/$CCGT_prefix.plink.ped >tmp.ped
mv tmp.ped $result/$CCGT_prefix.plink.ped 
# filter variants
plink --file $result/$CCGT_prefix.plink  --snps-only --freq --out $result/$CCGT_prefix.plink.ori_frq
plink --file $result/$CCGT_prefix.plink  --snps-only --maf 0.001 --biallelic-only  --make-bed --out $result/$CCGT_prefix.plink
# filter by mendel error rates <max per-trio error rate> <max per-variant error rate>
plink --bfile $result/$CCGT_prefix.plink  --keep-allele-order --me 1 1 --set-me-missing --make-bed --out $result/$CCGT_prefix.plink.nomendel
# filter by Missing genotype rates
plink --bfile $result/$CCGT_prefix.plink.nomendel  --keep-allele-order --geno 0.1 --mind 0.05 --make-bed --out $result/$CCGT_prefix.plink.nomendel.filter
# plink --bfile $result/$CCGT_prefix.plink.nomendel.filter --mind 0 --recode --tab --out tmp
# plink --bfile $result/$CCGT_prefix.plink.nomendel.filter --missing  --recode --tab --out tmp
# plink --file tmp --make-bed --out tmp1
# phasing by shapeit
out_pre=$result/$CCGT_prefix.plink.nomendel.filter
shapeit --input-bed $out_pre.bed $out_pre.bim $out_pre.fam \
	--input-map data/hapmap/shapeit4/maps/hg38/chr14.b38.gmap.gz \
	--thread 8 --force \
	--duohmm \
	--output-max $out_pre.haps $out_pre.sample
# --duohmm is used to refine family relation

# transfer shapeit output into plink format
shapeit -convert --input-haps $out_pre --output-vcf $out_pre.shapeit.vcf 
vcftools --vcf $out_pre.shapeit.vcf --plink --out $out_pre.shapeit.plink
sed -i 's/chr//g' $out_pre.shapeit.plink.map
# update ped file
perl src/modify_ped.pl data/all_CCGT.ped $out_pre.shapeit.plink.ped >tmp.ped
mv tmp.ped $out_pre.shapeit.plink.ped 
plink --file $out_pre.shapeit.plink --make-bed --out $out_pre.shapeit.plink
## ld+block
plink --bfile $out_pre.shapeit.plink --r2 --out $out_pre.shapeit.plink.ld
plink --bfile $out_pre.shapeit.plink --blocks 'no-pheno-req' --out $out_pre.shapeit.plink.blocks
# basic statistics
plink --bfile $out_pre.shapeit.plink --freq --out $out_pre.shapeit.plink.ori_frq
plink --bfile $out_pre.shapeit.plink --freq --hardy --hwe 0.001 --mendel --ibc --het --make-bed --out $out_pre.shapeit.plink
plink --bfile $out_pre.shapeit.plink --recode HV --out $out_pre.display
#############
# haplotype
pop_list="CHB China JPT EAS EUR AMR  AFR SAS ALL"
for i in $pop_list
do
	#perl src/hap_hg382hg19.pl result/PYGL_hg38/PYGL_1000g_$i.blocks.blocks.det test/PYGL_1000g_$i.blocks.blocks.det
	perl src/hap_hg192hg19.pl result/PYGL_hg19/PYGL_1000g_$i.blocks.blocks.det test/PYGL_1000g_$i.blocks.blocks.det
done
perl src/hap_hg382hg19.pl result/PYGL_hg38/CCGT_PYGL_WGS.hg38.plink.nomendel.filter.shapeit.plink.blocks.blocks.det test/PYGL_CCGT.blocks.blocks.det

# maf,result/PYGL_hg38/PYGL_1000g_AMR.plink.frq
for i in $pop_list
do
  #perl src/frq_hg382hg19.pl result/PYGL_hg38/PYGL_1000g_$i.plink.ori_frq.frq test/PYGL_1000g_$i.plink.frq &
  perl src/frq_hg192hg19.pl result/PYGL_hg19/PYGL_1000g_$i.plink.ori_frq.frq test/PYGL_1000g_$i.plink.frq result/PYGL_hg19/PYGL_1000g.plink.map &
done
perl src/frq_hg382hg19.pl result/PYGL_hg38//CCGT_PYGL_WGS.hg38.plink.ori_frq.frq  test/PYGL_CCGT.plink.frq result/PYGL_hg38/CCGT_PYGL_WGS.hg38.plink.map &

############ merge 1000g + CCGT
plink --bfile result/PYGL_hg38/PYGL_1000g_ALL.plink --bmerge $out_pre.shapeit.plink --make-bed --out result/PYGL_hg38/merge.plink 
plink --bfile result/PYGL_hg38/merge.plink --freq --hardy --hwe 0.001 --mendel --ibc --het --distance --ibs-matrix --genome --homozyg --make-bed --out result/PYGL_hg38/merge.plink
plink --bfile result/PYGL_hg38/merge.plink --cluster --make-bed --out result/PYGL_hg38/merge.plink

### for haplotype viewer
for i in $pop_list
do 
	plink --bfile result/PYGL_hg38/PYGL_1000g_$i.plink --recode HV --out test/$i
done	
plink --bfile $out_pre.shapeit.plink --extract result/PYGL_hg38/PYGL_1000g_ALL.plink.frq --make-bed --out $out_pre.shapeit.plink.filter

plink --bfile $out_pre.shapeit.plink.filter --recode HV --out test/CCGT
##
set JAVA_OPTS= -Xmx10240M -Xms5120M -XX:MaxPermSize=2560m  
java -jar /home/dongxinran/softwares/Haploview.jar
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-3.b12.el7_3.x86_64/jre/bin/java -Dsun.java2d.noddraw=true -Xmx10240m -classpath /home/dongxinran/softwares/Haploview.jar edu.mit.wi.haploview.HaploView

## merge ped
awk -F "\t" {'print $1"\t"$2"\tCCGT"'} data/all_CCGT.ped >test/merge.ped
pop_list="EAS EUR AMR AFR SAS"
for i in $pop_list
do
	awk -vnvar="$i" -F "\t" '{print $1"\t"$2"\t"nvar}' data/${i}_sample.2.txt >>test/merge.ped
done

## draw snp tree
prefix='result/PYGL_hg38/CCGT_PYGL_WGS.hg38.plink.nomendel.filter.shapeit'
plink --file $prefix.plink --recode transpose --out $prefix.tplink
perl src/convert2hapmap.pl --tped $prefix.tplink.tped --tfam $prefix.tplink.tfam --build=ncbi_38
## output $prefix.tplink.tped.hapmap
/home/dongxinran/tools/get_gene_genotype_vcf/src/SNPhylo/snphylo.sh -H $prefix.tplink.tped.hapmap -P $prefix


################## calculate sample relationship,ibd
platform='hg19'
result="/cluster/home/chenhy/project/autism/result/PYGL_${platform}/"
prefix='sample_rel'
ref_fa='/cluster/apps/refseq/GATK4/hg19/ucsc.hg19.fasta'
export PERL5LIB=//cluster/apps/software/vcftools_0.1.13/lib/perl5/site_perl/

# 1. merge vcf (--missing-to-ref)
vcf_file=`perl /cluster/home/dongxinran/tools/get_vcf.pl 16F5105,17F01663,17F06241,17F09093,19F08468,19F04567,19F03905,19F04988,19F05425,19F03457,19F07874,19Y039F,19F07825M,18F00573M,BPD-3F | cut -f 2`	
vcf_file1=`perl ./xinran_src/vcf2bgvcf.pl $result $vcf_file`
#bcftools merge --missing-to-ref --force-samples $vcf_file1 -o $result/$prefix.vcf
bcftools merge --force-samples $vcf_file1 -o $result/$prefix.vcf
rm $result/$prefix.vcf.gz;bgzip $result/$prefix.vcf;tabix $result/$prefix.vcf.gz
bcftools norm -f $ref_fa $result/$prefix.vcf.gz | bgzip -c >$result/$prefix.norm.vcf.gz
# 2. convert to plink
#bcftools filter -R $bed_file $result/$prefix.norm.vcf.gz
#bed_file='/cluster/apps/refseq/Gene_panel/Clear_seq/S0684402\ IHD/S0684402_Regions.bed'
bed_file='/cluster/apps/refseq/Gene_panel/Clear_seq/S0684402_IHD/S0684402_Regions_merge.bed'
vcftools --gzvcf $result/$prefix.norm.vcf.gz --bed $bed_file --plink --out $result/$prefix.plink
# 3. modify gender
# data/all_CCGT.ped
perl src/modify_ped.pl data/all_CCGT.ped $result/$prefix.plink.ped >tmp.ped
mv -f tmp.ped $result/$prefix.plink.ped
# 4. run plink
#plink --file $result/$prefix.plink  --genome --min 0.2 -snps-only --freq --maf 0.1 --exclude high_ld.txt --out $result/pihat_min0.2
# plink --file $result/$prefix.plink  --genome --min 0.2 --freq --exclude high_ld.txt --maf 0.01 --out $result/pihat_min0.2
##
plink --file $result/$prefix.plink -snps-only --indep-pairwise 50 5 0.2 --exclude high_ld.txt --out $result/$prefix.plink.prune
plink --file $result/$prefix.plink --maf 0.01 --genome --extract $result/$prefix.plink.prune.prune.in --min 0 --out $result/pihat_min0
# result/PYGL_hg19//sample_rel.tplink.tped.hapmap
# transfer
plink --file $result/$prefix.plink --extract $result/$prefix.plink.prune.prune.in --recode transpose --out $result/$prefix.tplink
perl src/convert2hapmap.pl  --tped $result/$prefix.tplink.tped --tfam $result/$prefix.tplink.tfam --build=ncbi_37
/home/dongxinran/tools/get_gene_genotype_vcf/src/SNPhylo/snphylo.sh -H $result/$prefix.tplink.tped.hapmap -P $result/$prefix

##
--genome invokes an IBS/IBD computation, and then writes a report with the following fields to plink.genome:

FID1	Family ID for first sample
IID1	Individual ID for first sample
FID2	Family ID for second sample
IID2	Individual ID for second sample
RT	Relationship type inferred from .fam/.ped file
EZ	IBD sharing expected value, based on just .fam/.ped relationship
Z0	P(IBD=0)
Z1	P(IBD=1)
Z2	P(IBD=2)
PI_HAT	Proportion IBD, i.e. P(IBD=2) + 0.5*P(IBD=1)
PHE	Pairwise phenotypic code (1, 0, -1 = AA, AU, and UU pairs, respectively)
DST	IBS distance, i.e. (IBS2 + 0.5*IBS1) / (IBS0 + IBS1 + IBS2)
PPC	IBS binomial test
RATIO	HETHET : IBS0 SNP ratio (expected value 2)


##
-HapMap file format:
The current release consists of text-table files only, with the following columns:

Col1: refSNP rs# identifier at the time of release (NB: it might merge 
		  with another rs# in the future)
Col2: SNP alleles according to dbSNP
Col3: chromosome that SNP maps to 
Col4: chromosome position of SNP, in basepairs on reference sequence
Col5: strand of reference sequence that SNP maps to
Col6: version of reference sequence assembly (currently NCBI build36)
Col7: HapMap genotyping center that produced the genotypes
Col8: LSID for HapMap protocol used for genotyping
Col9: LSID for HapMap assay used for genotyping
Col10: LSID for panel of individuals genotyped
Col11: QC-code, currently 'QC+' for all entries (for future use)
Col12 and on: observed genotypes of samples, one per column, sample
     identifiers in column headers (Coriell catalog numbers, example:
				       NA10847).
